% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\include{preamble}

\begin{document}
%
\title{Fantastic activists and how to find them\thanks{} \\ \small (not the real title)}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{affiliation 1 \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle       % typeset the header of the contribution
%
\begin{abstract}
last to be written
\keywords{Twitter analytics \and online user discovery \and online activists \and online influencers \and influence theories}
\end{abstract}
%

%
%
\section{Introduction}

In this paper we present a generic and customisable software framework for incrementally discovering and ranking individual profiles for classes of online users, through analysis of their social activity in micro-blogging platforms, specifically Twitter.

\subsection{Motivation} \label{sec:motivation}

Practical motivation for this work comes from our ongoing effort to support health officers in tropical countries, specifically in Brazil, in their fight against airborne virus epidemics like Dengue and Zika, which are carried by mosquitoes. Help from community activists is badly needed to supplement the scarce public resources deployed on the ground. Our past work has therefore focused on identifying relevant content on Twitter that may point health authorities directly to mosquito breeding sites~\cite{Sousa2018}, or to users who have given some sign of interest in those topics, i.e., by posting relevant content on Twitter~\cite{Missier2017}. 

The approach described in this paper generalises those past efforts, by attempting to discover users who demonstrate an inclination to become engaged in social issues, regardless of specific topics.
We refer to this class of users as \textit{activists}.
The rationale for this approach is that activists who manifest themselves online on a range of social initiatives, may be more sensitive to requests for help on specific issues, such as controlling tropical epidemics \anote{FLAVIO: I would still specify that we search in related broader topics such as healthcare. otherwise seems too optimistic (?)}.

To be clear, this work is not about providing a robust definition of online activism, or to demonstrate that online activism translates into actual engagement in the ``real world''.
%
Instead, we acknowledge that the notion of activist is not as well formalised in the literature as that of, for example, \textit{influencers}. 
Thus, we have developed a generic content processing pipeline which can be customised to target specific users contexts. 
The pipeline repeatedly searches for and ranks Twitter user profiles and collects a rich set of quantifiable network- and content-based user metrics. 
Thus, once targeted to a topic the pipeline provides a tool for exploring various concrete definitions of user roles, including online activism, i.e., by combining the metrics into higher level user features to be used for ranking.

We begin by arguing for the need for a new discovery process for this class of users, and then present the pipeline as our main research contribution.
%
According to the Cambridge Dictionary, an \textit{activist} is ``A person who believes strongly in political or social change and takes part in activities such as public protests to try to make this happen''.
%
While activism is well-documented, e.g. in the social movement literature~\cite{doi:10.1080/14742830701497277}, and online activism is a well-known phenomenon \cite{IJoC1246}, research has been limited to the study of its broad societal impact. 
In contrast, we are interested in the fine-grained discovery of activists at the level of the single individual, that is, we seek people who feel passionate about a cause or topic, and who take action for it. 
Searching for online activists is a realistic goal, as activists presence in social media is widely acknowledged, and it is also clear that social media facilitates activists communication and organization \cite{Poell2014,Youmans2012}. 
Specific traits that characterise activists include awareness of causes and social topic and the organization of social gatherings and activities, including in emergency situations, by helping organize support efforts and diffusion of useful information.
 
Informal as it sounds, this characterisation of online activism is different enough from that of \textit{influencer} to merit its own definition.
According to ~\cite{Kardara2015}, \textit{influencers are prominent individuals with special characteristics that enable them to	affect a disproportionately large number of their peers with their actions.}
A large number of metrics and techniques have been proposed to make this generic definition operational~\cite{RIQUELME2016949}. These are mostly based on metrics of network centrality, along with metrics derived from the users' online activity, i.e., number of retweets or other users' content, number of retweets of own content, and many more.
%
Algorithms to find influencers favour high visibility profiles, typically across global networks.
In contrast, activists are typically low-key, less prominent users who only emerge from the crowd by signalling high levels of engagement with one or more specific topics, as opposed to being thought-leaders. \anote{FLAVIO: do we need a citation here or simple rephrasing?}
%
While we believe that specific activist behaviour can be characterised using some of the well-tested quantifiable metrics known from the literature cited above~\cite{RIQUELME2016949}, it should also be clear that the way such metrics are combined to identify activist profiles are not the same as for influencers. 

\subsection{Challenges}

Motivated by these observations, our search for activists faces a number of challenges.
%
Firstly, we note that, given their potentially more subdue nature, it is intuitively more difficult to separate their online footprint from the background noise of general conversations, than it is for an influencer.
Also, interesting activists are by their nature associated to specific topics and manifest their nature in local contexts, for instance as organisers or participants to local events. 
Finally, we expect personal engagement to be sustained over time and across multiple such contexts. 
These observations suggest that the models and algorithms developed for influencers are not immediately applicable, because they mostly operate on global networks, where less prominent users have less of a chance to emerge.
Some topic-sensitive metrics and models have been proposed to measure social influence, for example, \textit{alpha centrality}~\cite{Bonacich2001,Overbey2013}, and the \textit{Information Diffusion} model~\cite{Pal2011}. Algorithms based on topic models have also been proposed to account for topic specificity~\cite{Zhao2011b}. However, these approaches are still aimed at measuring influence, not activism, and assume a one-shot discovery process, as opposed to a continuous, incremental approach.

\subsection{Approach}

To address these challenges, the approach we propose involves two strategies. 
Firstly, we identify suitable contexts that are topic-specific and limited both in time and, optionally, also in space, i.e., regional initiatives, events, or campaigns.
We then search for users only within these contexts, using a combination of network and content metrics. 
This follows the intuition that low-key users who produce weak online signal have a better chance to be discovered when the search is localised and then repeated across multiple such contexts.
By \textit{continuously discovering new contexts} and searching for users engaged in those events and campaigns, we hope to incrementally build up a users' database where users who appear in multiple contexts are progressively more strongly characterised.
%
Secondly, to allow experimenting with varying technical definitions of \textit{activist}, we collect a number of network-based and content-based user profile raw features, and make it available for mining. The raw features can be combined into more complex engineered features which in turn can be used to filter and rank users in various ways.

\subsection{ Contributions}
The paper makes the following specific contributions.
%
Firstly, we propose a data processing pipeline for harvesting Twitter content and user profiles, based on multiple limited contexts. 
The pipeline includes community detection and network analysis algorithms aimed at discovering users within such limited contexts.

Secondly, we have implemented a comprehensive set of content-based metrics that results into an ever-growing database of user profile features, which can then be used for mining purposes. 
User profiles are updated when they are repeatedly found in multiple contexts.

Lastly, for empirical evaluation of our implementation, we demonstrate an operational definition of the activist profile, defined in terms of the features available in the database, by collecting \hl{XX} users across \hl{YY} contexts in the \hl{XX} domain. 
\comment{Note that application of the approach to contexts specific to Zika is ongoing and is not reported at this stage of the research}{unless we can do it in time}


\subsection{Reference case study and running example} \label{sec:reference}

\anote{the health care events and campaigns used as running examples.
	
	justify why Zika campaigns are not used. Too specific, only regional?

clarify our evaluation is not based on ground truth}


\subsection{Related Work}


\anote{topic-specific influencers. cite \cite{Schenk2011} SCHENK 2011}\\
	
\anote{\cite{Kardara2015} KARDARA:
	Here a new ranking algorithm is proposed to find local influencers on Twitter that appear within the context of a specific event being discussed, incorporating the network dynamics as the event evolves with time. 
	Local to an event context but focus on user reputation. 
	The above techniques all attempt to define influence as
	some measurable attribute or observation in the network, such as how many times an original story appears on a website, or how centrally connected a node is within various defined modules within the networks.
	The definition used in this work for influence is “who is being listened to the most”.
	- this is not who we are looking for.
	- one single large event
	- no breakdown into communities
}\\


\anote{\cite{Bizid:2015:PUD:2808797.2809411} BIZID
	user prominence on and off topic.
	searches for specific metrics that can be computed in real time
}

%%%%%%%%%%%%%%%%%%%%%
\section{Contexts and user metrics}
%%%%%%%%%%%%%%%%%%%%%


%Two sets of criteria are used to establish relevance.
%Firstly, a context defined by a combination of spatio-temporal and keyword / hashtag constraints to describe the social topics of interest, for instance ``social health care campaigns'' or ``Zika awareness day in Rio de Janeiro''.
%%
%Secondly, a set of metrics are specified to characterise the relevance of user profiles for a specific domain, along with a user-defined function that is specific to user roles, for instance ``activist'', to compose the features into a single value, i.e., a relevance score, which can then be used to rank user profiles both within and across contexts.
%The metrics are meant to capture some operational definition of relevance for specific kinds of user roles. 

The aim of the pipeline is to repeatedly and efficiently discover user profiles from the Twitter post history within user-specified contexts,\footnote{Our plan is automate context discovery in the next phase of this work.} and use the process to grow a database of feature-rich user profiles that can be used to rank users according to user-defined relevance functions. 
The criteria used to define contexts, profile relevance functions, and associated user relevance thresholds can be configured for specific applications.

\subsection{Contexts and Context networks} \label{sec:contexts}

As described In Sec.~\ref{sec:reference}, contexts are meant to identify events or campaigns around social issues, which are characterised by temporal boundaries and by hashtags and/or keyword terms, and optionally also by spatial constraints, i.e., specified using a geographical bounding box.
These are \textit{weak} contexts, because Twitter does not natively support the notion of event or campaign (unlike, for example, Facebook, Instagram, or Meetup).
We denote a generic context as
\begin{equation}
C = \langle s, [t_1, t_2], K \rangle 
\label{eq:context}
\end{equation}
where $s$ represents the optional spatial constraint, $[t_1, t_2]$ a time interval, and $K = \{ k_1 \dots k_n\}$ is the set of terms used to filter content within the spatio-temporal boundaries.
%
$C$ defines search criteria, which produce a set $P(C)$ of posts when submitted to Twitter.
We only consider two Twitter activities: an \textit{original tweet}, or a \textit{retweet}.
Let $u(p)$ be the user who originated a tweet $p \in P(C)$.
We say that both $p$ and $u(p)$ are \textit{within context} $C$.

We also define the complement $\Tilde{P}(C)$ of $P(C)$ as the set of posts found using the same spatio-temporal constraints, but which do not contain any of the terms in $K$. More precisely, given a context $C'= \langle s, [t_1, t_2], \emptyset \rangle$ with no terms constraints, we define $\Tilde{P}(C) = P(C') \setminus P(C)$. 
We refer to these posts, and their respective users, as ``out of context $C$''.

The set of posts $P(C)$ induces a user-user social network graph $G_C = (V,E)$ where $V$ is the set of all users who have authored any $p \in P(C)$: 
$V = \{ u(p) | p \in P(C) \}$, and a weighted edge $e = \langle u_1, u_2, w \rangle$ is added to $E$ for each pair of posts $p_1, p_2$ such that $u(p_1) = u_1, u(p_2) = u_2$ and 
either (i) $p_2$ is a retweet of $p_1$, or (ii) $p_1$ contains a mention of $u_2$.
For any such edge, the weight $w$ is a count of such pairs of posts occuring in $P(C)$ for the same pair of users.

\subsection{User relevance metrics}  \label{sec:metrics}

We support a number of metrics that are generally accepted by the community as forming a core, from which many different social user roles are derived~\cite{RIQUELME2016949}. 
We distinguish amongst three types of features, which differ in the way they are computed from the raw Twitter feed:
\begin{description}
	\item[Content-based metrics] that rely solely on content and not on the user-user graph topology. These metrics are defined relative to a topic of interest, i.e., a context;
	\item[Context-independent topological metrics] that encode context-independent, long-lived relationships amongst users, i.e., follower/followee; and 
	\item[Context-specific topological metrics] that encode user relationships that occur specifically within a context.
\end{description}

All metrics are functions of a few core features that can be directly extracted from Twitter posts. 
We start with a set of features that are commonly used in the literature as a baseline.
Given a context $C$ containing user $u$, we define:
%
\begin{align*}
\mathit{R1}(u) &\text{: Number of retweets by $u$, of tweets from other in-context users;}\\
\mathit{R2}(u)&\text{: Number of unique users in $C$, who have been retweeted by $u$;}\\
\mathit{R3}(u)&\text{: Number of retweets of $u$'s tweets;}\\
\mathit{R4}(u)&\text{: Number of unique users in $C$ who retweeted $u$'s tweets;}\\
\mathit{P1}(u)&\text{: Number of original posts by $u$ within $C$;}\\
\mathit{P2}(u)&\text{: Number of web links found in original posts by $u$ within $C$;} \\
\mathit{F1}(u)& \text{: Number of followers of $u$;}\\
\mathit{F2}(u)& \text{: Number of followees of $u$}
\end{align*}
%

Note that, given $C$, we can evaluate each of the features above with respect to either $P(C)$ or  $\Tilde{P}(C)$ independently from each other, that is, we can consider a ``on-context'' and an ``off-context'' version of each feature.
%
For example, we are going to write $R1_{on}(u)$ to denote the number of context retweets and $R1_{\mathit{off}}(u)$ the number of out-of-context retweets by $u$, i.e., these are retweets that occur within $C$'s spatio-temporal boundaries, but do not contain any of the hashtags or keywords that define $C$.  
%
We similarly qualify all other features.
%
Using these core features, we have implemented the following metrics.

For \textbf{content-based metrics}, we have:
\begin{align}
\textit{Topical Focus:~\cite{Missier2017}:} ~ \mathit{TF}(u) & =  \frac{\mathit{P1}_{\mathit{on}}(u)}{\mathit{P1}_{\mathit{off}}(u) +1}    \label{eq:TF}\\
\textit{Topical Strength~\cite{Bizid2018}:} ~\mathit{TS}(u) & =	\frac{\mathit{P2}_{\mathit{on}}(u) \cdot \log(\mathit{P2}_{\mathit{on}}(u) + R3_{\mathit{on}} +1 )}{\mathit{P2}_{\mathit{off}}(u) \cdot \log(\mathit{P2}_{\mathit{off}}(u) + R3_{\mathit{off}} +1 ) + 1}   \label{eq:TS} \\
\textit{Topical Attachment~\cite{Bizid:2015,Poell2014}:} ~\mathit{TA}(u) & = \frac{\mathit{P1}_{\mathit{on}}(u) + \mathit{P2}_{\mathit{on}}(u)}{\mathit{P1}_{\mathit{off}}(u) + \mathit{P2}_{\mathit{off}}(u) +1} \label{eq:TA}
\end{align}

We implement one \textbf{Context-independent topological metric} and one \textbf{Context-specific topological metric}, both commonly used, see e.g.~\cite{RIQUELME2016949}:
\begin{align}
\textit{Follower Rank:}  \quad \mathit{FR}(u) = \frac{\mathit{F1}(u)}{\mathit{F1}(u)+\mathit{F2}(u)}   \label{eq:FR}\\
\textit{In-degree centrality:} \quad \mathit{IC}(u) = \frac{\mathit{indegree}(u)}{N-1}  \label{eq:IDC}
\end{align}
where $N$ is the number of nodes in the network induced by $C$.

Note that the metrics we have selected are a superset of those indicated in recent studies on online activism, namely \cite{Lotan2011} and \cite{Poell2014}, and thus support our empirical evaluation, described in Sec.~\ref{sec:evaluation}.

%%%%%%%%%%%%%%%%%%%%
\section{Incremental User Discovery} \label{sec:Pipeline}
%%%%%%%%%%%%%%%%%%%%

The content processing pipeline operates iteratively on a set of contexts, one at the time, that is dynamically updated at the end of each iteration, starting from an initial set of seed contexts.
The user discovery process is therefore potentially open-ended, as long as new contexts can be discovered, as explained below.
Each iteration takes a context $C$  as input, and generates a list of users who participate in $C$, along with the complete set of their features and metrics as described above. 
The users profiles are added to a database, where entries for repeat users are updated according to a user-defined function. 
The final step in the iteration involves semi-automatically discovering new contexts, thus making further iterations possible.
%
The pipeline structure and data flow are illustrated in Fig. ~\ref{fig:twitterframework}.

\begin{figure*}
	\centering
	\includegraphics[width=0.7\linewidth]{figures/TwitterFramework}
	\caption{\comment{Schematic diagram of the user discovery framework }{this is a placeholder -- to be redrawn -PM }}
	\label{fig:twitterframework}
\end{figure*}

\subsection{Harvesting Content and Creating Context networks}  \label{sec:harvesting}

Firstly, all Twitter posts $P(C)$ that satisfy the criteria set in $C$ are retrieved, using either the Search or the Streaming Twitter APIs.\footnote{Repeat queries are required to get around the well-known Twitter API limitations for retrieving tweets.}

Secondly, the context network $G_C$ is generated as defined in Sec.~\ref{sec:contexts}. To recall, this is a directed network representing retweet and/or mention interactions between pairs of users in $C$. 
The size of the network is largely determined by the nature of the context, and may range from a few \hl{XX} users for a small context such as a local awareness event, to \hl{XX} users for a large national event that extends over a long timeframe, such as a political election campaign.


\subsection{Community detection}  \label{sec:communities}

Next, the context network graph $G_C$  is partitioned into communities of users.
The goal of this partitioning is to further narrow the scope for the topology-sensitive metrics, namely FollowerRank (\ref{eq:FR}) and in-degree centrality (\ref{eq:IDC}), 
and thus to enable weak-signal users to emerge relative to other more globally dominant users.
%
Many different approaches have been proposed to discover virtual communities in social networks. 
We have chosen {DEMON}~\cite{Coscia:2012:DLD:2339530.2339630} because it allows communities to overlap to a degree that is tunable, making it an ideal feature to identify users who may be active in more than one community within the same context, i.e., a social event or a campaign.

{DEMON} identifies communities that a person belongs to with \textit{ego networks}, which consists of an individual, called the ego, and all the persons the ego has a social relationship with. 
As each ego network considers a node and its neighbours only, it provides a local method for discovering user affiliations, thus more akin to a social context.
%
It has been suggested~\cite{Arnaboldi2013} that ego networks are a useful model not only to describe social relationships amongst people offline, but also the structure of their online connections. 
Recognising that any individual may have different types of social relationships with different people (i.e., family, friends, colleagues, etc.),  {DEMON}  naturally allows for an individual to participate in multiple communities. 

The locality principle of ego networks translates into an efficient algorithm for discovering overlapping communities in a social graph. 
Specifically, {DEMON} operates on one node $v$ at a time in our context network $G_C$.

It applies a \textit{label propagation} algorithm to each neighbour $v'$ of $v$, as follows. First, a new label $l$, which identifies a new community, is tentatively assigned to $v'$. 
	Then, with probability $\alpha$ $v'$ changes its label to that of the majority of its own neighbours. 
	At this point, each of $v$'s neighbours has a label, which is either new of that of the majority of its own neighbours (excecpt $v$ itself).
	$v$ is then assigned majority labels amongst those of its neighbours. 
	This determines $v$'s community. 
	When more than one label has the same count, $v$ is assigned to all of those communities.
%
As a final step, communities that overlap by more than some percentage $\epsilon $ are merged.

Note that users who do not belong to any community are discarded from the whole process.
Once communities are identified, we calculate  in-degree centrality (\ref{eq:IDC}) for each node locally, \textit{relative to their own community}.

\comment{In our evaluation we have experimented with varying values for parameters $\alpha$ an $\epsilon$...}{do we plan to say anything on how to tune them?}

\anote{what happens when nodes belong to more than one community?}

\subsection{Computing user features and ranking}  \label{sec:features}

The next step in the process involves retrieving the core features and then the user relevance metrics as defined in Sec. ~\ref{sec:metrics}, for each user in each of the communities.

As this involves querying the Twitter API for many user profiles, this step hits the limitations imposed by Twitter \anote{be specific}.
To get around this problem, we have implemented a dedicated component to \textit{scrape} user information directly from their profile Web pages, namely:
\begin{itemize}
	\item personal information: the name of the user, the link to its website, the bio and the date the user joined Twitter.
	\item profile statistics: the number of tweets published, and the number of followers $F1(u)$ as well as of followees, $F2(u)$.
\end{itemize}
The latter are used directly to compute  the \textit{Follower Rank} metric (\ref{eq:FR}).
To compute the other metrics: \textit{Topical Focus} (\ref{eq:TF}), \textit{Topical Strength} (\ref{eq:TS}), \textit{Topical Attachment} \ref{eq:TA}, we further need to retrieve the entire user post history for the entire time interval defined by the context.
These posts are then separated into $P(C)$ (on-context) and $\Tilde{P}(C)$ (off-context), depending on whether they contain a hashtag related to the context or not.
Similarly, a post that contains a link is a \textit{link on-topic} that contains both a link and an hashtag related to the context, and a \textit{link off-topic} otherwise.
Note that we also calculate the number of retweets for every post, i.e., $\mathit{R1}(u)$ and $\mathit{R3}(u)$, which are required to compute \textit{Topical Strength}.

All of these features are persisted to a database which is made available for ranking purposes.
When a user already appears in the database, i.e., from previous iterations, a user-defined function can be specified to update the set of features. 
For instance, one such function could just store the average over multiple occurrences of the same user across iterations, of each of the features as well as of the metrics.
Alternatively, the database allows for the series of features values to be stored, making it possible to analyse them over time.

The main purpose of the database is to enable data analytics on a growing set of users, whose history of engagement may extend over multiple events or campaigns.
In particular, ranking is achieved by specifying a user-defined function, as described in Fig.~\ref{fig:twitterframework}, which is a function of the metrics and generates a relevance score for each user.
Note that this ``framework'' approach is consistent with the experimental nature of our search for \textit{activists}, which requires exploring a variety of ranking functions.

\subsection{Context discovery} \label{sec:context-discovery}

The final step in the iteration aims to discover new contexts. 
The idea is that, once a score function has been applied and users have been ranked, we can hope to discover new interesting keywords and hashtags in the timeline of the top-$k$ users.
Specifically,  we consider each hashtag found in the timelines, which is related to the broader topic and not yet considered in past iterations.
Each stored hashtag is then enriched with the information needed to perform a new iteration of the pipeline, namely (i) the temporal and spatial information of the context, and (ii) related hashtags.

Currently this step is only semi-automated, as it requires a human to make a judgement on the relevance of the new terms. 
One can easily imagine this step to completely automated, however, and this is one of the items for our current work.

While the process ends naturally when no new contexts are uncovered from the previous ones, the system continuously monitors the Twitter stream for recent contexts. These may typically include events that are temporally recurring, and use similar hashtags for each new edition. In this case, their relevance is assessed on the basis of their past history.


\section{Empirical Evaluation} \label{sec:evaluation}

We have clarified in the introduction that our approach top discovering interesting users is \textit{unsupervised}. 
Unlike most paper on user discovery, we do not make use of expert-generated ground truth, which would inevitably be biased by the specific experts' own opinion. 
Instead, we aim to create a feature-rich and comprehensive database of users to which a variety of user-defined ranking functions can be applied, possibly yielding very different results. 

Thus, our evaluation aims to show that the process is effective in building up such a database, and is articulated in two phases. 
Firstly, we use a manually-picked selection of meaningful contexts from the same social domain, namely public healthcare campaigns, to demonstrate network construction, breakdown of each  context network into communities, and harvesting of users from each community, along with their metrics.
Secondly, we provide examples of ranking functions that we believe to capture the notion of  \textit{online activists}, and we empirically validate them by inspecting the profiles of representative top-k users.

 \subsection{Contexts, networks, and communities}  \label{sec:contexts}
 
 
 \anote{FLAVIO:
 	\begin{itemize}
 		\item describe context of choice "UK healthcare campaigns"
 		\item harvesting content and creating context networks
 		\begin{itemize}
 			\item table of each event harvested together with a description (like on report 10)
 			\item table for each event describing the related graphs (\#nodes, \#edges, avg weighted degree)
 		\end{itemize}
 		\item community detection:
 		\begin{itemize}
 			\item describe the avg \# of nodes per community, avg \# of edges per community, avg \# of users that belongs to more than one community(?)
 			\item partition qualities avg: internal density, avg degree, FOMD, cut ratio and expansion (chosen because more suitable for overlapping commmunity detection algorithms https://github.com/Lab41/survey-community-detection)
 		\end{itemize}
 	\end{itemize}
 }
 
 
 We have manually selected 25 contexts within the scope of healthcare campaigns in the UK, all occurring in 2018. 
These are listed in Table~\ref{tab:contexts}.
Contexts are either time-limited events or public health awareness campaigns, and are well-characterised using predefined hashtags as shown in the Table.

In Fig \hl{XXX} we report summary statistics for the 25 user-user networks constructed by harvesting posts for each context. 
We can notice that \hl{XXX}...

Next, we report on the effect of the two community detection algorithms mentioned earlier, namely \textit{Demon} and \textit{Girwan-Newman}, on each of the networks. 
As we can see, Demon either identifies a very small number of small communities, and only retains users who belong to at least one community, or it ``disintegrates'' the network into degenerate, one-node communities. 
In this latter case, our pipeline disregards the communities and computes the users' topological metrics on the whole network.
In order to decide whether the comunities are usable, we use a number of metrics that quantify partition quality, namely  the \textit{internal density} and \hl{XXX}.

\anote{comment on Girwan-Newman when data becomes available}

\begin{table}
\begin{center}
	\framebox{list all contexts}
	\end{center}
		
	Summary of events:   \\
	no\_edges, \\
	no\_nodes, \\
	avg\_degree, \\
	connectivity: no\_SSC \ no\_nodes
	\caption{Summary of contexts used in the experiments}
	\label{tab:contexts}
\end{table}	 

\begin{table}
\begin{center}	\framebox{summary stats for communities} \end{center}
	
		fraction of networks that ``disintegrate'' into atomic commuities using Demon\\
		fraction of networks that are broken down into meaningful  communities \\
		avg number of communities per network (for the good ones) \\
		avg fraction of users that survive as community members\\
		summary of community quality metrics to show how we can set a threshold and automatically reject poor communities 		
	\caption{Summary statistics of context networks and their communities}
	\label{tab:networks}
\end{table}	 

\subsection{Users discovery}  \label{sec:users}



\anote{FLAVIO:
	\begin{itemize}
		\item User selection and ranking:
		\begin{itemize}
			\item feature 2-3 different ranking functions
			\item briefly describe the number inside functions (example: the \# of events a user is in, the \# of communities a user is in, indegree cetrality)
			\item decide over a method for comparison for the functions (list top-k users for each function and look for them over twitter, check how selective are and the diagram wrt \#users)
		\end{itemize} 
		\item new context discovery (?)
	\end{itemize}
}
 
Finally, from each context we extract all users who are either part of a community, or in the case of non-meaningful communities, all users in the network.
Using these criteria, a total of \hl{XX} users has been added to the database.
It is interesting to note that out of those, 160 users appear in more than one context. 
Of those, 115 are found within the entire context network, and 45 are selected as being part of (at least) one community.
Overall, 5 repeat users appear in 4 different contexts, 18 appear in 2 contexts, and the remaining 137 appear in two contexts (all other users only appear in one context).  
Table~\ref{tab:repeat-users} reports the top repeat users with a brief description of their profile. 

The chart in Fig.~\ref{fig:repeat-users-frequency} shows the number of repeat users per context. 

\anote{comment on whether these are individuals or well-known organisations}

\begin{table}
	\centering
	\framebox{table content here}
	\caption{Top-k repeat users, amongst those identified as belonging to some community.}
	\label{tab:networks}
\end{table}	 

\begin{figure*}
	\centering
	\includegraphics[width=0.7\linewidth]{figures/repeat-users-frequency}
	\caption{Number of repeat users broken down by context}
	\label{fig:repeat-users-frequency}
\end{figure*}

  
	
\section{Discussion and ongoing work}

\anote{
	we say that events are manually identified. Sketch the events bootstrapping idea.
}

\anote{FLAVIO:
	\begin{itemize}
		\item unsupervised learning?
	\end{itemize}
}

 \bibliographystyle{splncs04}
 \bibliography{icwe19}

\end{document}
